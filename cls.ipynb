{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "datadir = './abstrct/AbstRCT_corpus/data/train/neoplasm_train'\n",
    "testdir = './abstrct/AbstRCT_corpus/data/test/neoplasm_test'\n",
    "\n",
    "train_raw_files = [ f for f in os.listdir(datadir) if f.endswith('.txt') ]\n",
    "train_ann_files = [ f for f in os.listdir(datadir) if f.endswith('.ann') ]\n",
    "\n",
    "test_raw_files = [ f for f in os.listdir(testdir) if f.endswith('.txt') ]\n",
    "test_ann_files = [ f for f in os.listdir(testdir) if f.endswith('.ann') ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_annotated(fpath):\n",
    "    res = []\n",
    "    with open(fpath, 'r') as infile:\n",
    "        for row in infile.readlines():\n",
    "            row = row.strip()\n",
    "            if re.match('^T\\d', row):\n",
    "                name, annotation, text = row.split('\\t')\n",
    "                fname = os.path.basename(fpath).replace('.ann', '')    \n",
    "                name = f'{fname}-{name}'\n",
    "                is_arg, start, end = annotation.split()\n",
    "                start = int(start)\n",
    "                end = int(end)\n",
    "                res.append((name, is_arg, start, end, text))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "train_ann_dict = defaultdict(list)\n",
    "test_ann_dict = defaultdict(list)\n",
    "\n",
    "for f in train_ann_files:\n",
    "    fname = f.replace('.ann', '')\n",
    "    filepath = os.path.join(datadir, f)\n",
    "    train_ann_dict[fname] = extract_annotated(filepath)\n",
    "    \n",
    "for f in test_ann_files:\n",
    "    fname = f.replace('.ann', '')\n",
    "    filepath = os.path.join(testdir, f)\n",
    "    test_ann_dict[fname] = extract_annotated(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ann_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ann_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dict = {}\n",
    "for f in train_raw_files:\n",
    "    with open(os.path.join(datadir, f), 'r') as infile:\n",
    "        raw_dict[f.replace('.txt', '')] = infile.read().strip()\n",
    "        \n",
    "test_raw_dict = {}\n",
    "for f in test_raw_files:\n",
    "    with open(os.path.join(testdir, f), 'r') as infile:\n",
    "        test_raw_dict[f.replace('.txt', '')] = infile.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_raw_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The majority of prostate carcinoma survivors experience enduring sexual difficulties and associated distress in the years after definitive treatment. A counseling intervention aimed at improving levels of sexual satisfaction and increasing successful utilization of medical treatment for erectile dysfunction (ED) was developed and pilot-tested for both the survivor of prostate carcinoma and his partner. All male participants were 3-month to 5-year survivors of localized prostate carcinoma who had been treated with radical prostatectomy or radiation therapy, and were married or in a committed relationship. Couples were randomized to attend four sessions of counseling together or to have the man attend alone. In both groups, partners completed behavioral homework. The sessions included education on prostate carcinoma and sexual function and options to treat ED as well as sexual communication and stimulation skills. Standardized questionnaires at baseline, posttreatment, and at 3-month and 6-month follow-up assessed sexual function, marital adjustment, psychologic distress, and utilization of treatments for ED. Fifty-one of 84 couples randomized to treatment completed the intervention (61%). Attendance by the partner did not affect outcomes. Participants completing the intervention demonstrated improvement in male overall distress (P < 0.01), male global sexual function (P < 0.0001), and female global sexual function (P < 0.05) at 3-month follow-up, but regression toward baseline was noted at 6-month follow-up. However, utilization of ED treatments increased from 31% at the time of study entry to 49% at the 6-month follow-up (P = 0.003). The results of this brief pilot counseling intervention demonstrated significant gains in sexual function and satisfaction and increased utilization of treatments for ED. However, modifications are needed in future randomized trials to reduce the rate of premature termination and to improve long-term maintenance of gains.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dict['16294343']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(sent1, sent2):\n",
    "    first = nltk.word_tokenize(sent1)  # from \"Hello world\" to [\"Hello\", \"world\"]\n",
    "    second = nltk.word_tokenize(sent2)\n",
    "    # print(first)\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    # { } is a set in python: unique values\n",
    "    x = {w for w in first if w not in stopwords.words('english')}\n",
    "    y = {w for w in second if w not in stopwords.words('english')}\n",
    "    # print(x)\n",
    "\n",
    "    rvector = x.union(y)  # put everything together\n",
    "\n",
    "    l1 = [1 if w in x else 0 for w in rvector]  # [1,1,0,0,1]\n",
    "    l2 = [1 if w in y else 0 for w in rvector]  # [0,1,1,0,1]\n",
    "\n",
    "    c = 0\n",
    "    for i in range(len(rvector)):\n",
    "        c += l1[i] * l2[i]\n",
    "\n",
    "    cosine = c / float((sum(l1) * sum(l2))**0.5)\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences(raw_dict, ann_dict):\n",
    "    data = []\n",
    "    for fname, raw_text in raw_dict.items():\n",
    "        sentences = nltk.sent_tokenize(raw_text.strip())\n",
    "        arguments = [x[1] for x in ann_dict[fname]]\n",
    "        annotated = [x[4] for x in ann_dict[fname]]\n",
    "        for sent1 in sentences:\n",
    "            match = ''\n",
    "            similarity = 0\n",
    "            annotated_argument = ''\n",
    "            for arg, sent2 in zip(arguments, annotated):\n",
    "                cs = cosine_similarity(sent1, sent2)\n",
    "                if cs > similarity and cs > 0.8:\n",
    "                    similarity = cs\n",
    "                    match = sent2\n",
    "                    annotated_argument = arg\n",
    "                    break\n",
    "            \n",
    "            if not match:\n",
    "                is_argumentative = 0\n",
    "            else:\n",
    "                is_argumentative = 1\n",
    "                \n",
    "            data.append((sent1, is_argumentative, annotated_argument))\n",
    "    return data\n",
    "            \n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = extract_sentences(raw_dict, train_ann_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = extract_sentences(test_raw_dict, test_ann_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4418\n",
      "1258\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2471"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(filter(lambda x: x[1] == 0, train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The majority of prostate carcinoma survivors experience enduring sexual difficulties and associated distress in the years after definitive treatment.',\n",
       " 0,\n",
       " '')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train_data, columns=['text', 'label', 'arg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>arg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The majority of prostate carcinoma survivors e...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A counseling intervention aimed at improving l...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All male participants were 3-month to 5-year s...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Couples were randomized to attend four session...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In both groups, partners completed behavioral ...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label arg\n",
       "0  The majority of prostate carcinoma survivors e...      0    \n",
       "1  A counseling intervention aimed at improving l...      0    \n",
       "2  All male participants were 3-month to 5-year s...      0    \n",
       "3  Couples were randomized to attend four session...      0    \n",
       "4  In both groups, partners completed behavioral ...      0    "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              2471\n",
       "Premise       1318\n",
       "Claim          572\n",
       "MajorClaim      57\n",
       "Name: arg, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['arg'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(test_data, columns=['text', 'label', 'arg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>arg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There are few reports about the course of vest...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In this study, we present prospectively collec...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The aim was to measure the effect of GKRS comp...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Secondary end points were postinclusion additi...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The patients underwent magnetic resonance imag...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label arg\n",
       "0  There are few reports about the course of vest...      0    \n",
       "1  In this study, we present prospectively collec...      0    \n",
       "2  The aim was to measure the effect of GKRS comp...      0    \n",
       "3  Secondary end points were postinclusion additi...      0    \n",
       "4  The patients underwent magnetic resonance imag...      0    "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tok = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tok.tokenize(text)\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    lemmas = [lemmatiser.lemmatize(t.lower(), pos='v') for t in tokens]\n",
    "    return [k for k in lemmas if k not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train['text'], train['label']\n",
    "x_test, y_test = test['text'], test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2471\n",
       "1    1947\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    670\n",
       "1    588\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = TfidfVectorizer(analyzer=preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf = vectoriser.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4418, 5336)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5336 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tfidf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf_scores = cross_val_score(sgd_clf, x_train_tfidf, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80656109, 0.7918552 , 0.8020362 , 0.82672707, 0.80747452])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8069308148383494 +/- 0.022690178009372564\n"
     ]
    }
   ],
   "source": [
    "print(f'{sgd_clf_scores.mean()} +/- {sgd_clf_scores.std() * 2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf_pred = cross_val_predict(sgd_clf, x_train_tfidf, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2077,  394],\n",
       "       [ 459, 1488]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, sgd_clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SGDClassifier(random_state=42),\n",
       "             param_grid={'early_stopping': [True, False],\n",
       "                         'fit_intercept': [True, False],\n",
       "                         'loss': ['hinge', 'log', 'squared_hinge'],\n",
       "                         'penalty': ['l2', 'l1', 'none']})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = {'fit_intercept': [True, False],\n",
    "        'early_stopping': [True, False],\n",
    "        'loss': ['hinge', 'log', 'squared_hinge'],\n",
    "        'penalty': ['l2', 'l1', 'none']\n",
    "}\n",
    "\n",
    "search = GridSearchCV(estimator=sgd_clf, param_grid=grid, cv=5)\n",
    "search.fit(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping': True,\n",
       " 'fit_intercept': False,\n",
       " 'loss': 'log',\n",
       " 'penalty': 'l2'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sgd_clf_scores = cross_val_score(search.best_estimator_, x_train_tfidf, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8239052899668449"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_sgd_clf_scores.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
