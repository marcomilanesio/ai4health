{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdEu4aFr7EwI"
   },
   "source": [
    "## Argument Mining Practical Session\n",
    "\n",
    "## PART II - Glove\n",
    "\n",
    "To use this on Colab, run the following cells. (Authentication required).\n",
    "\n",
    "**IMPORTANT**: the folder `share` exists on **my** Google Drive. Make sure to change this with a folder of your choice on your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1PAtUQQ4XRp",
    "outputId": "11fcf06b-ca35-4a67-aaf3-6d569ab1e1e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above should result in an `already mounted` message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folder `share` exists on my Google Drive. I navigate to this folder to store there the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtmnvrYp5iBe",
    "outputId": "718e8314-4ac8-4107-a101-c7949e668018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive/share\n"
     ]
    }
   ],
   "source": [
    "%cd gdrive/MyDrive/share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBaZ0hMe7Tq2"
   },
   "source": [
    "Make sure you have the content downloaded in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPSe0d2c54uT",
    "outputId": "a75da12f-885e-4ec9-8711-144eb3b00a3a"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then (if you want) you can delete from your Google Drive all the extracted files **except** the file `glove_6B_100d.txt`. This will be the one we use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_-bwMTC7bwg"
   },
   "source": [
    "We're good to go.\n",
    "\n",
    "## Premise vs Claim Classification\n",
    "\n",
    "**IMPORTANT** If you run locally (NOT COLAB) start from here.\n",
    "\n",
    "Let's begin with some imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYxqdaIK7CaN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I spare you some time by importing functions we implemented in the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "datadir = './abstrct/AbstRCT_corpus/data/train/neoplasm_train'\n",
    "annotated = [f for f in os.listdir(datadir) if f.endswith('.ann')]\n",
    "\n",
    "testdir = './abstrct/AbstRCT_corpus/data/test/neoplasm_test'\n",
    "testannotated = [f for f in os.listdir(testdir) if f.endswith('.ann')]\n",
    "\n",
    "def extract_annotated(fpath):\n",
    "    res = []\n",
    "    with open(fpath, 'r') as infile:\n",
    "        for row in infile.readlines():\n",
    "            row = row.strip()\n",
    "            if re.match('^T\\d', row):\n",
    "                name, annotation, text = row.split('\\t')\n",
    "                fname = os.path.basename(fpath).replace('.ann', '')    \n",
    "                name = f'{fname}-{name}'\n",
    "                is_arg, start, end = annotation.split()\n",
    "                start = int(start)\n",
    "                end = int(end)\n",
    "                res.append((name, is_arg, start, end, text))\n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ArgumentMining_AI4HEALTH.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
